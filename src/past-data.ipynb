{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2723d2f-0b5e-4a2f-82b6-66372155ad7e",
   "metadata": {},
   "source": [
    "# Big 5 European Leagues - Fixtures Data\n",
    "\n",
    "**Data Source:** https://www.football-data.co.uk/data.php\n",
    "\n",
    "In this notebook, I have scraped data from the source website using the Beautiful Soup package. I intend to utilize this code to pull data directly from the source website, save it to a CSV file, and perform analysis on the data.\n",
    "\n",
    "I am extracting the entire data from all the seasons, beginning from 1993-94 until 2022-23.\n",
    "\n",
    "**Big 5 European Leagues:**\n",
    "- Premier League (England)\n",
    "- Bundesliga (Germany)\n",
    "- Serie A (Italy)\n",
    "- Ligue 1 (France)\n",
    "- La Liga (Spain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228fe98e-3a6b-41ea-8411-2544ba636ec5",
   "metadata": {},
   "source": [
    "# 1. Loading the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8554dba9-f4e0-43d7-8069-07352d936004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib.parse\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import date\n",
    "from pandas.errors import ParserError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f738c9f5-04d6-4601-927c-e34d94fb81a1",
   "metadata": {},
   "source": [
    "# 2. Selecting countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c57052-d601-4b49-b519-bda6876875a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting countries of the leagues for which I want to extract the data.\n",
    "\n",
    "countries = [\"england\", \"germany\", \"italy\", \"france\", \"spain\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4ddf56-4734-4fc2-ac06-a0d70a528807",
   "metadata": {},
   "source": [
    "# 3. Assigning the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfea773-9182-46bb-824a-41e7e6af2dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning parts of URL to various variables to be used later in the Beautiful Soup functions.\n",
    "\n",
    "base_url = \"https://www.football-data.co.uk/\" \n",
    "end_url = \"m.php\"\n",
    "start_of_url = \"mmz4281/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00dfaa7-48cf-4bb2-9e64-5b2e4b2c8e07",
   "metadata": {},
   "source": [
    "# 4. Selecting Seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59acc9b-1796-4874-bfb0-71035c032493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of seasons for which the data will be extracted only.\n",
    "\n",
    "start_date = date(2023, 7, 1)\n",
    "start_year = start_date.year\n",
    "current_date = date.today()\n",
    "current_year = current_date.year\n",
    "number_of_years = current_year - start_year\n",
    "seasons = []\n",
    "\n",
    "for i in range(number_of_years + 1):\n",
    "    season_concat = str(start_year + i)[-2:] + str(start_year + i + 1)[-2:]\n",
    "    seasons.append(season_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e09db68-e452-4e08-bdbc-2d4182bcdc0f",
   "metadata": {},
   "source": [
    "# 5. Using Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb23bfb4-2269-4745-972b-faa5c311766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Beautiful Soup to identify the list of links from where the data will be extracted.\n",
    "\n",
    "all_links_joined = []\n",
    "for country in countries:\n",
    "# Requesting the URL\n",
    "    country_url = urllib.parse.urljoin(base_url, (country + end_url))\n",
    "    data = requests.get(country_url)\n",
    "# Creating object of BeautifulSoup\n",
    "    soup = BeautifulSoup(data.text)\n",
    "# Identifying all the links from where data will be extracted.\n",
    "    all_links = [link[\"href\"] for link in soup.find_all(\"a\") \n",
    "                          if link[\"href\"].startswith(start_of_url)\n",
    "                          and link[\"href\"][-4:] == \".csv\" \n",
    "                          and link[\"href\"][-6:] != \"E2.csv\" \n",
    "                          and link[\"href\"][-6:] != \"E3.csv\" \n",
    "                          and link[\"href\"][-6:] != \"EC.csv\"]\n",
    "# Identifying all the links according to the seasons criteria.\n",
    "    for link in all_links:\n",
    "        joined_url = urllib.parse.urljoin(base_url, link)\n",
    "        year = link.split(\"/\")[-2]\n",
    "        if not year in seasons:\n",
    "            all_links_joined.append(joined_url)\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017b8f77-e48a-4e48-b44a-981d2b9bbda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all the links from where data will be extracted.\n",
    "\n",
    "all_links_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96bcb9d-c0d1-44d3-b873-ceaa550076ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The total number of links from where data will be extracted.\n",
    "\n",
    "len(all_links_joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e410129-4793-45a6-9e86-3bb479fdc3e8",
   "metadata": {},
   "source": [
    "# 6. Initializing the format of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d9a8d6-1d32-4e50-bb7e-9f84b1f1f527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading the data from the first link to a pandas dataframe. To be referenced later to append other fixtures data properly.\n",
    "\n",
    "# Changing the format of the season value\n",
    "year_for_df = all_links_joined[0].split(\"/\")[-2]\n",
    "year_for_df = year_for_df[:2] + \"-\" + year_for_df[-2:]\n",
    "\n",
    "# Uploading the data to the dataframe using pandas and inserting a column named \"Season\" to the dataframe.\n",
    "df_concat = pd.read_csv(all_links_joined[0])\n",
    "df_concat.insert(loc = 0, column = \"Season\", value = year_for_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55c2a7f-f409-48ac-b824-fc57e104aac4",
   "metadata": {},
   "source": [
    "# 7. Appending the entire data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29982909-4d39-4c84-832d-d65acf4357d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending the data together from all the links.\n",
    "\n",
    "for link in all_links_joined[1:]:\n",
    "    filename = link.split(\"/\")[-1]\n",
    "    year = link.split(\"/\")[-2]\n",
    "    year_filename = year + filename\n",
    "    try:\n",
    "# Reading the CSV file to append the data.\n",
    "        df = pd.read_csv(link, encoding = \"unicode_escape\")\n",
    "# To delete the duplicate columns in some of the files. \n",
    "        df = df.loc[:, ~df.columns.duplicated()].reset_index(drop = True)\n",
    "# To resolve the tokenization error in some of the files due to mismatch of number of columns in some of the rows.\n",
    "    except ParserError:\n",
    "        df = pd.read_csv(link, encoding = \"unicode_escape\", sep = \"\\t\")\n",
    "# Saving the CSV file to correct the errors.\n",
    "        df.to_csv(year_filename, index = False)\n",
    "# Opening the CSV file and calculating the maximum number of columns.\n",
    "        with open(year_filename, \"r\") as temp_f:\n",
    "            col_count = [len(l.split(\",\")) for l in temp_f.readlines()]\n",
    "        column_names = [i for i in range(max(col_count))]        \n",
    "# Reading the CSV file again to append the correct data.\n",
    "        df = pd.read_csv(link, encoding = \"unicode_escape\", names = column_names)\n",
    "# Correcting the headers of the file\n",
    "        headers = df.iloc[0].values\n",
    "        df.columns = headers\n",
    "        df.drop(index = 0, axis = 0, inplace = True)\n",
    "        os.remove(year_filename)\n",
    "# To delete the duplicate columns in some of the files.\n",
    "        df = df.loc[:, ~df.columns.duplicated()].reset_index(drop = True)\n",
    "# To keep a track of the progress of the data extraction from the links.\n",
    "    print(year)\n",
    "# Inserting a column named \"Season\" to the dataframe.\n",
    "    df.insert(loc = 0, column = \"Season\", value = (year[:2] + \"-\" + year[-2:]))\n",
    "# Appending the data to the dataframe.\n",
    "    df_concat = pd.concat([df_concat, pd.DataFrame(df)], ignore_index = True)  \n",
    "    time.sleep(1)\n",
    "# Removing all the null rows\n",
    "df_concat.dropna(subset = \"Div\", axis = 0, inplace = True)\n",
    "# Removing all the null columns and irrelevant columns\n",
    "df_concat = df_concat.iloc[:, :25]\n",
    "# Renaming the league names\n",
    "df_concat[\"Div\"] = df_concat[\"Div\"].replace({\"E0\": \"Premier League\", \"E1\": \"EFL Championship\",\n",
    "                                             \"D1\": \"Bundesliga\", \"D2\": \"Bundesliga 2\",\n",
    "                                             \"I1\": \"Serie A\", \"I2\": \"Serie B\",\n",
    "                                             \"SP1\": \"LaLiga\", \"SP2\": \"LaLiga 2\",\n",
    "                                             \"F1\": \"Ligue 1\", \"F2\": \"Ligue 2\"})\n",
    "\n",
    "# Saving the extracted data from all the links to CSV file\n",
    "df_concat.to_csv(\"past-data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efab8c4-aca6-453f-aae2-3cf71175e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the number of matches per season to ensure the data extracted is correct.\n",
    "\n",
    "season_matches_count = df_concat.groupby([\"Season\", \"Div\"]).count().iloc[:, 0].reset_index()\n",
    "season_matches_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f91bab2-7db4-43b3-b561-f75826883fb4",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
